{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read\n",
    "import openl3\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import random\n",
    "\n",
    "\n",
    "def set_seed():\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "uniq_labels = np.sort(np.unique(train_df['label']))\n",
    "label_encoder = {label: i for i, label in enumerate(uniq_labels)}\n",
    "label_decoder = {i: label for i, label in enumerate(uniq_labels)}\n",
    "\n",
    "emb_model = openl3.models.load_embedding_model(input_repr=\"mel256\", content_type=\"music\", embedding_size=512)\n",
    "\n",
    "\n",
    "class Masked_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        losses = F.log_softmax(y_pred.cuda()) * y_true.cuda()\n",
    "        return -losses.sum() / 41.\n",
    "\n",
    "\n",
    "class Augmentations():\n",
    "    def __init__(self, sr):\n",
    "        self.energy_boosting_prob = 0.5 # топ рузультат - 0.5\n",
    "        self.random_noise_prob = 0\n",
    "        self.mixup_prob = 1\n",
    "        self.sr = sr\n",
    "\n",
    "    def energy_boosting(self, wav):\n",
    "        if np.random.rand() < self.energy_boosting_prob:\n",
    "            return wav * np.random.uniform(0.5, 2.0)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def random_noise(self, wav):\n",
    "        if np.random.rand() < self.random_noise_prob:\n",
    "            return wav + np.float32(np.random.rand(wav.shape[0]))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def mixup(self, wav, each_class_wav, label):\n",
    "        if np.random.rand() < self.mixup_prob:\n",
    "            lam = np.random.beta(0.4, 0.4)\n",
    "            if lam < 0.5:\n",
    "                lam += 0.5\n",
    "            augm_class = np.random.randint(41)\n",
    "            res_label = np.array(label)\n",
    "            if res_label.argmax() != augm_class:\n",
    "                res_label[res_label.argmax()] = lam\n",
    "                res_label[augm_class] = 1 - lam\n",
    "                return wav * lam + (1 - lam) * each_class_wav[augm_class], res_label\n",
    "            else:\n",
    "                return wav, res_label\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "def pad_to_format(wav, sr, targ_sec):\n",
    "    wav = np.array(wav)\n",
    "    if wav.shape[0] / sr > targ_sec:\n",
    "        start_point = np.random.randint(0, wav.shape[0] - targ_sec * sr)\n",
    "        wav = wav[start_point:start_point + targ_sec * sr]\n",
    "    else:\n",
    "        wav = np.hstack((wav, np.zeros(targ_sec * sr - len(wav))))\n",
    "    return wav\n",
    "\n",
    "\n",
    "def make_label_matrix(labels):\n",
    "    mab_matrix = []\n",
    "    for label in labels:\n",
    "        lab_vec = np.zeros(41)\n",
    "        lab_vec[label] = 1\n",
    "        mab_matrix.append(lab_vec)\n",
    "    return mab_matrix\n",
    "\n",
    "\n",
    "def make_augmentation(x, y):\n",
    "    examples = []\n",
    "    final_x, final_y = [], []\n",
    "    for lab in list(label_decoder.keys()):\n",
    "        examples.append([x[i] for i in range(len(x)) if y[i].argmax() == lab])\n",
    "    augmentator = Augmentations(16000)\n",
    "    for i in range(len(x)):\n",
    "        augm_1_result = augmentator.energy_boosting(x[i])\n",
    "        augm_2_result = augmentator.random_noise(x[i])\n",
    "        rand_examples = [examples[i][np.random.randint(len(examples[i]))] for i in range(41)]\n",
    "        augm_3_result, soft_y = augmentator.mixup(x[i], rand_examples, y[i])\n",
    "\n",
    "        final_x.append(x[i])\n",
    "        final_y.append(y[i])\n",
    "        if augm_1_result is not None:\n",
    "            final_x.append(augm_1_result)\n",
    "            final_y.append(y[i])\n",
    "        if augm_2_result is not None:\n",
    "            final_x.append(augm_2_result)\n",
    "            final_y.append(y[i])\n",
    "        if augm_3_result is not None:\n",
    "            final_x.append(augm_3_result)\n",
    "            final_y.append(soft_y)\n",
    "    return np.array(final_x), np.array(final_y)\n",
    "\n",
    "\n",
    "class EventDetectionDataset(Dataset):\n",
    "    def __init__(self, x, y=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.anom_prob = 0.2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # добавить сюда prepare_shape()\n",
    "        if self.y is not None:\n",
    "            return self.x[idx], self.y[idx]\n",
    "        return self.x[idx]\n",
    "\n",
    "\n",
    "class VeryDumb(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense_1 = nn.Linear(512, 1024)\n",
    "        self.dense_2 = nn.Linear(1024, 2048)\n",
    "        self.dense_3 = nn.Linear(2048, 512)\n",
    "        self.dense_4 = nn.Linear(512, 41)\n",
    "        self.do_1 = nn.Dropout(0.2)\n",
    "        self.do_2 = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.dense_1(x))\n",
    "        x = F.tanh(self.dense_2(x))\n",
    "        x = self.do_1(x)\n",
    "        x = F.tanh(self.dense_3(x))\n",
    "        x = self.do_2(x)\n",
    "        x = self.dense_4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def calc_feature(x, sr):\n",
    "    features = []\n",
    "    for wav in x:\n",
    "        emb, ts = openl3.get_embedding(wav, sr, emb_model, hop_size=1, center=False)\n",
    "        features.append(emb.mean(axis=0))\n",
    "    return features\n",
    "\n",
    "\n",
    "def train():\n",
    "    train_df = pd.read_csv('train.csv')\n",
    "    train_folder = 'audio_train/train'\n",
    "    sample_rate = 16000\n",
    "    x, y = [], []\n",
    "    for i in range(train_df.shape[0]):\n",
    "        sr, wav_data = read(os.path.join(train_folder, train_df['fname'].iloc[i]))\n",
    "        wav_data = pad_to_format(wav_data, sr, 2)\n",
    "        x.append(wav_data)\n",
    "    y = list(train_df['label'])\n",
    "    y = [label_encoder[i] for i in y]\n",
    "    x_tr, x_val, y_tr, y_val = train_test_split(x, y, stratify=y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    \n",
    "    y_tr = make_label_matrix(y_tr)\n",
    "    y_val = make_label_matrix(y_val)\n",
    "    x_tr, y_tr = make_augmentation(x_tr, y_tr)\n",
    "    x_tr = calc_feature(x_tr, sample_rate)\n",
    "    x_val = calc_feature(x_val, sample_rate)\n",
    "    \n",
    "    pickle.dump(x_tr, open('openl3_augmented/train_features.pickle', 'wb'))\n",
    "    pickle.dump(x_val, open('openl3_augmented/validate_features.pickle', 'wb'))\n",
    "\n",
    "    x_tr = pickle.load(open('openl3_augmented/train_features.pickle', 'rb'))\n",
    "    x_val = pickle.load(open('openl3_augmented/validate_features.pickle', 'rb'))\n",
    "    y_tr = pickle.load(open('openl3_augmented/train_targets.pickle', 'rb'))\n",
    "    y_val = pickle.load(open('openl3_augmented/validate_targets.pickle', 'rb'))\n",
    "\n",
    "    train_dset = EventDetectionDataset(x_tr, y_tr)\n",
    "    val_dset = EventDetectionDataset(x_val, y_val)\n",
    "    train_loader = DataLoader(train_dset, batch_size=200, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dset, batch_size=200, shuffle=False, num_workers=0)\n",
    "\n",
    "    network = VeryDumb().cuda()\n",
    "    optimizer = optim.SGD(network.parameters(), lr=1e-2)\n",
    "    loss_f = Masked_Loss()\n",
    "\n",
    "    n_epoch = 500\n",
    "\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    top_score = 0\n",
    "    top_epoch = 0\n",
    "    for e in range(n_epoch):\n",
    "        print('epoch #', e)\n",
    "        loss_list = []\n",
    "        outputs = []\n",
    "        targets = []\n",
    "        for i_batch, sample_batched in enumerate(train_loader):\n",
    "            x, y = sample_batched\n",
    "            x = torch.Tensor(np.float32(x)).view(x.shape[0], x.shape[1]).cuda()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = network(x)\n",
    "            outputs.append(output.detach().cpu().numpy().argmax(axis=1))\n",
    "\n",
    "            target = y\n",
    "            targets.append(target.argmax(axis=1))\n",
    "\n",
    "            loss = loss_f(output, target.cuda().long())\n",
    "            loss_list.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        y_true = np.hstack(targets)\n",
    "        y_pred = np.hstack(outputs)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        train_loss.append(np.mean(loss_list))\n",
    "        train_acc.append(acc)\n",
    "        print('mean train loss:', train_loss[-1])\n",
    "        print('train accuracy:', acc)\n",
    "\n",
    "        loss_list = []\n",
    "        outputs = []\n",
    "        targets = []\n",
    "        with torch.no_grad():\n",
    "            for i_batch, sample_batched in enumerate(val_loader):\n",
    "                x, y = sample_batched\n",
    "                x = torch.Tensor(np.float32(x)).view(x.shape[0], x.shape[1]).cuda()\n",
    "\n",
    "                output = network(x)\n",
    "                outputs.append(output.detach().cpu().numpy().argmax(axis=1))\n",
    "\n",
    "                target = y\n",
    "                targets.append(target.argmax(axis=1))\n",
    "\n",
    "                loss = loss_f(output, target.cuda().long())\n",
    "                loss_list.append(loss.item())\n",
    "\n",
    "            y_true = np.hstack(targets)\n",
    "            y_pred = np.hstack(outputs)\n",
    "            acc = accuracy_score(y_true, y_pred)\n",
    "            val_loss.append(np.mean(loss_list))\n",
    "            val_acc.append(acc)\n",
    "            print('mean val loss:', val_loss[-1])\n",
    "            print('val accuracy:', acc)\n",
    "        if e % 40 == 0:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] *= 1e-1\n",
    "        if e % 100 == 0:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = 1e-2\n",
    "        if acc > top_score:\n",
    "            torch.save(network.state_dict(), 'openl3_augmented.pt')\n",
    "            top_score = acc\n",
    "            top_epoch = e\n",
    "\n",
    "\n",
    "\n",
    "def test():\n",
    "    test_df = pd.read_csv('sample_submission.csv')\n",
    "    test_folder = 'audio_test/test'\n",
    "    sample_rate = 16000\n",
    "    x = []\n",
    "    for i in range(test_df.shape[0]):\n",
    "        sr, wav_data = read(os.path.join(test_folder, test_df['fname'].iloc[i]))\n",
    "        wav_data = pad_to_format(wav_data, sr, 2)\n",
    "        x.append(wav_data)\n",
    "\n",
    "    x = calc_feature(x, sample_rate)\n",
    "    pickle.dump(x, open('openl3_augmented/test_features.pickle', 'wb'))\n",
    "\n",
    "    network = VeryDumb().cuda()\n",
    "    checkpoint = torch.load('openl3_augmented.pt')\n",
    "    network.load_state_dict(checkpoint)\n",
    "    network.eval()\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    test_dset = EventDetectionDataset(x, np.zeros((len(x), 41)))\n",
    "    test_loader = DataLoader(test_dset, batch_size=200, shuffle=False, num_workers=0)\n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(test_loader):\n",
    "            x, y = sample_batched\n",
    "            x = torch.Tensor(np.float32(x)).view(x.shape[0], x.shape[1]).cuda()\n",
    "            output = network(x)\n",
    "            outputs.append(output.detach().cpu().numpy().argmax(axis=1))\n",
    "        y_pred = np.hstack(outputs)\n",
    "        real_pred = []\n",
    "        for i in range(len(y_pred)):\n",
    "            real_pred.append(label_decoder[y_pred[i]])\n",
    "        test_df['label'] = real_pred\n",
    "        test_df.to_csv('submit_augmented_fc.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "set_seed()\n",
    "train()\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
